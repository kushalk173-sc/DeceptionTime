{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deception Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We import our datasetand our dependencies, into the model. In the only step of data removal, we remove post market data from here, as the market does not follow the system of "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ltp</th>\n",
       "      <th>volume</th>\n",
       "      <th>bidqty</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>askqty</th>\n",
       "      <th>short</th>\n",
       "      <th>buy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-01 09:15:00</td>\n",
       "      <td>1043.40</td>\n",
       "      <td>13573</td>\n",
       "      <td>2</td>\n",
       "      <td>1043.65</td>\n",
       "      <td>1044.90</td>\n",
       "      <td>98</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-04-01 09:15:01</td>\n",
       "      <td>1043.85</td>\n",
       "      <td>600</td>\n",
       "      <td>84</td>\n",
       "      <td>1043.85</td>\n",
       "      <td>1044.75</td>\n",
       "      <td>1</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-04-01 09:15:02</td>\n",
       "      <td>1044.95</td>\n",
       "      <td>1242</td>\n",
       "      <td>10</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>1044.25</td>\n",
       "      <td>144</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-04-01 09:15:03</td>\n",
       "      <td>1044.95</td>\n",
       "      <td>2441</td>\n",
       "      <td>159</td>\n",
       "      <td>1043.55</td>\n",
       "      <td>1044.60</td>\n",
       "      <td>392</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-01 09:15:04</td>\n",
       "      <td>1043.00</td>\n",
       "      <td>2072</td>\n",
       "      <td>196</td>\n",
       "      <td>1043.05</td>\n",
       "      <td>1043.55</td>\n",
       "      <td>25</td>\n",
       "      <td>-0.95</td>\n",
       "      <td>1.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381748</th>\n",
       "      <td>2021-04-29 15:29:54</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>263</td>\n",
       "      <td>1446</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>780</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381749</th>\n",
       "      <td>2021-04-29 15:29:54</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1446</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>780</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381750</th>\n",
       "      <td>2021-04-29 15:29:56</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>52</td>\n",
       "      <td>1396</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>778</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381751</th>\n",
       "      <td>2021-04-29 15:29:57</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1396</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>778</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381752</th>\n",
       "      <td>2021-04-29 15:29:58</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>770</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380346 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 timestamp      ltp  volume  bidqty      bid      ask  askqty  \\\n",
       "0      2021-04-01 09:15:00  1043.40   13573       2  1043.65  1044.90      98   \n",
       "1      2021-04-01 09:15:01  1043.85     600      84  1043.85  1044.75       1   \n",
       "2      2021-04-01 09:15:02  1044.95    1242      10  1043.45  1044.25     144   \n",
       "3      2021-04-01 09:15:03  1044.95    2441     159  1043.55  1044.60     392   \n",
       "4      2021-04-01 09:15:04  1043.00    2072     196  1043.05  1043.55      25   \n",
       "...                    ...      ...     ...     ...      ...      ...     ...   \n",
       "381748 2021-04-29 15:29:54  1185.50     263    1446  1185.50  1185.75     780   \n",
       "381749 2021-04-29 15:29:54  1185.50       0    1446  1185.50  1185.75     780   \n",
       "381750 2021-04-29 15:29:56  1185.75      52    1396  1185.50  1185.75     778   \n",
       "381751 2021-04-29 15:29:57  1185.75       0    1396  1185.50  1185.75     778   \n",
       "381752 2021-04-29 15:29:58  1185.75       8    1396  1185.50  1185.75     770   \n",
       "\n",
       "        short   buy  \n",
       "0        1.05  1.10  \n",
       "1        1.30  0.40  \n",
       "2        0.70  1.15  \n",
       "3        1.55  0.00  \n",
       "4       -0.95  1.60  \n",
       "...       ...   ...  \n",
       "381748   0.25  0.25  \n",
       "381749   0.25  0.25  \n",
       "381750   0.25  0.25  \n",
       "381751   0.25  0.25  \n",
       "381752   0.25  0.25  \n",
       "\n",
       "[380346 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json(r'Stock Data/adaniTrain.json')\n",
    "#df = df.head(100000)\n",
    "n = int(df['ltp'][1]/100)\n",
    "#df = df.drop(['short', 'buy','act'], axis = 1)\n",
    "\n",
    "#create results column, 3 ticks ahead \n",
    "short = df.bid.shift(-1)\n",
    "buy = df.ask.shift(-1)\n",
    "df= df.assign(short=df.ask - short)\n",
    "df= df.assign(buy= -1*df.bid + buy)\n",
    "df = df[df['short'] < n ]\n",
    "df = df[df['buy'] <  n]\n",
    "df = df[df['short'] >  -1*n]\n",
    "df = df[df['buy'] > - 1*n]\n",
    "\n",
    "#remove outliers\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:54: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.2.0 and strictly below 2.4.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.4.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We add momentum indicators. These momentum indicators help us add information to the model. Such indicators are proven and are widely used in the markets. We have added the 13 indicators to help us analyze the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>ltp</th>\n",
       "      <th>volume</th>\n",
       "      <th>bidqty</th>\n",
       "      <th>bid</th>\n",
       "      <th>ask</th>\n",
       "      <th>askqty</th>\n",
       "      <th>short</th>\n",
       "      <th>buy</th>\n",
       "      <th>pltp</th>\n",
       "      <th>...</th>\n",
       "      <th>kelchd</th>\n",
       "      <th>std</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>vwap</th>\n",
       "      <th>ROC</th>\n",
       "      <th>CCI</th>\n",
       "      <th>force</th>\n",
       "      <th>chalkin</th>\n",
       "      <th>mass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1617268525000000000</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>2325</td>\n",
       "      <td>47</td>\n",
       "      <td>1042.95</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>1073</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1042.60</td>\n",
       "      <td>...</td>\n",
       "      <td>1043.475</td>\n",
       "      <td>0.816582</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>1042.60</td>\n",
       "      <td>1043.873803</td>\n",
       "      <td>-0.000814</td>\n",
       "      <td>51.433927</td>\n",
       "      <td>-1976.25</td>\n",
       "      <td>1780.215352</td>\n",
       "      <td>7.148487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1617268526000000000</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>3513</td>\n",
       "      <td>95</td>\n",
       "      <td>1043.40</td>\n",
       "      <td>1043.75</td>\n",
       "      <td>110</td>\n",
       "      <td>1.10</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>...</td>\n",
       "      <td>1043.420</td>\n",
       "      <td>0.795543</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>1043.855582</td>\n",
       "      <td>-0.000527</td>\n",
       "      <td>44.414101</td>\n",
       "      <td>-1932.15</td>\n",
       "      <td>1780.215352</td>\n",
       "      <td>7.171809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1617268527000000000</td>\n",
       "      <td>1043.25</td>\n",
       "      <td>1735</td>\n",
       "      <td>134</td>\n",
       "      <td>1042.65</td>\n",
       "      <td>1043.15</td>\n",
       "      <td>60</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>...</td>\n",
       "      <td>1043.345</td>\n",
       "      <td>0.769722</td>\n",
       "      <td>1043.45</td>\n",
       "      <td>1043.25</td>\n",
       "      <td>1043.842990</td>\n",
       "      <td>-0.000718</td>\n",
       "      <td>15.590041</td>\n",
       "      <td>-1301.25</td>\n",
       "      <td>-116.559371</td>\n",
       "      <td>7.042269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1617268528000000000</td>\n",
       "      <td>1043.30</td>\n",
       "      <td>454</td>\n",
       "      <td>5</td>\n",
       "      <td>1043.35</td>\n",
       "      <td>1043.75</td>\n",
       "      <td>65</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1043.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1043.170</td>\n",
       "      <td>0.485455</td>\n",
       "      <td>1043.30</td>\n",
       "      <td>1043.25</td>\n",
       "      <td>1043.840051</td>\n",
       "      <td>-0.001675</td>\n",
       "      <td>12.359536</td>\n",
       "      <td>-794.50</td>\n",
       "      <td>386.942012</td>\n",
       "      <td>6.714468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1617268529000000000</td>\n",
       "      <td>1043.70</td>\n",
       "      <td>885</td>\n",
       "      <td>66</td>\n",
       "      <td>1043.65</td>\n",
       "      <td>1044.15</td>\n",
       "      <td>95</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1043.30</td>\n",
       "      <td>...</td>\n",
       "      <td>1043.160</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>1043.70</td>\n",
       "      <td>1043.30</td>\n",
       "      <td>1043.838589</td>\n",
       "      <td>-0.000096</td>\n",
       "      <td>38.145640</td>\n",
       "      <td>-88.50</td>\n",
       "      <td>603.883112</td>\n",
       "      <td>6.623140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381748</th>\n",
       "      <td>1619710194000000000</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>263</td>\n",
       "      <td>1446</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>780</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1185.870</td>\n",
       "      <td>0.520256</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1155.138855</td>\n",
       "      <td>-0.000506</td>\n",
       "      <td>-57.663880</td>\n",
       "      <td>-157.80</td>\n",
       "      <td>-233.516763</td>\n",
       "      <td>11.674090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381749</th>\n",
       "      <td>1619710194000000000</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1446</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>780</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1185.875</td>\n",
       "      <td>0.515994</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1155.138855</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-19.380063</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-233.516763</td>\n",
       "      <td>10.967341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381750</th>\n",
       "      <td>1619710196000000000</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>52</td>\n",
       "      <td>1396</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>778</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>...</td>\n",
       "      <td>1185.840</td>\n",
       "      <td>0.510882</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1155.138863</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>13.049338</td>\n",
       "      <td>-18.20</td>\n",
       "      <td>-46.818280</td>\n",
       "      <td>10.228997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381751</th>\n",
       "      <td>1619710197000000000</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>0</td>\n",
       "      <td>1396</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>778</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1185.870</td>\n",
       "      <td>0.493964</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>1155.138863</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>13.496272</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-46.818280</td>\n",
       "      <td>9.740015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381752</th>\n",
       "      <td>1619710198000000000</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>8</td>\n",
       "      <td>1396</td>\n",
       "      <td>1185.50</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>770</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>...</td>\n",
       "      <td>1185.900</td>\n",
       "      <td>0.474342</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>1185.75</td>\n",
       "      <td>1155.138865</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>14.054567</td>\n",
       "      <td>2.40</td>\n",
       "      <td>-46.818280</td>\n",
       "      <td>8.844098</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>379671 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp      ltp  volume  bidqty      bid      ask  \\\n",
       "25      1617268525000000000  1043.45    2325      47  1042.95  1043.45   \n",
       "26      1617268526000000000  1043.45    3513      95  1043.40  1043.75   \n",
       "27      1617268527000000000  1043.25    1735     134  1042.65  1043.15   \n",
       "28      1617268528000000000  1043.30     454       5  1043.35  1043.75   \n",
       "29      1617268529000000000  1043.70     885      66  1043.65  1044.15   \n",
       "...                     ...      ...     ...     ...      ...      ...   \n",
       "381748  1619710194000000000  1185.50     263    1446  1185.50  1185.75   \n",
       "381749  1619710194000000000  1185.50       0    1446  1185.50  1185.75   \n",
       "381750  1619710196000000000  1185.75      52    1396  1185.50  1185.75   \n",
       "381751  1619710197000000000  1185.75       0    1396  1185.50  1185.75   \n",
       "381752  1619710198000000000  1185.75       8    1396  1185.50  1185.75   \n",
       "\n",
       "        askqty  short   buy     pltp  ...    kelchd       std     High  \\\n",
       "25        1073   0.05  0.80  1042.60  ...  1043.475  0.816582  1043.45   \n",
       "26         110   1.10 -0.25  1043.45  ...  1043.420  0.795543  1043.45   \n",
       "27          60  -0.20  1.10  1043.45  ...  1043.345  0.769722  1043.45   \n",
       "28          65   0.10  0.80  1043.25  ...  1043.170  0.485455  1043.30   \n",
       "29          95   0.70  0.10  1043.30  ...  1043.160  0.471876  1043.70   \n",
       "...        ...    ...   ...      ...  ...       ...       ...      ...   \n",
       "381748     780   0.25  0.25  1185.75  ...  1185.870  0.520256  1185.75   \n",
       "381749     780   0.25  0.25  1185.50  ...  1185.875  0.515994  1185.50   \n",
       "381750     778   0.25  0.25  1185.50  ...  1185.840  0.510882  1185.75   \n",
       "381751     778   0.25  0.25  1185.75  ...  1185.870  0.493964  1185.75   \n",
       "381752     770   0.25  0.25  1185.75  ...  1185.900  0.474342  1185.75   \n",
       "\n",
       "            Low         vwap       ROC        CCI    force      chalkin  \\\n",
       "25      1042.60  1043.873803 -0.000814  51.433927 -1976.25  1780.215352   \n",
       "26      1043.45  1043.855582 -0.000527  44.414101 -1932.15  1780.215352   \n",
       "27      1043.25  1043.842990 -0.000718  15.590041 -1301.25  -116.559371   \n",
       "28      1043.25  1043.840051 -0.001675  12.359536  -794.50   386.942012   \n",
       "29      1043.30  1043.838589 -0.000096  38.145640   -88.50   603.883112   \n",
       "...         ...          ...       ...        ...      ...          ...   \n",
       "381748  1185.50  1155.138855 -0.000506 -57.663880  -157.80  -233.516763   \n",
       "381749  1185.50  1155.138855  0.000042 -19.380063     0.00  -233.516763   \n",
       "381750  1185.50  1155.138863 -0.000295  13.049338   -18.20   -46.818280   \n",
       "381751  1185.75  1155.138863  0.000253  13.496272     0.00   -46.818280   \n",
       "381752  1185.75  1155.138865  0.000253  14.054567     2.40   -46.818280   \n",
       "\n",
       "             mass  \n",
       "25       7.148487  \n",
       "26       7.171809  \n",
       "27       7.042269  \n",
       "28       6.714468  \n",
       "29       6.623140  \n",
       "...           ...  \n",
       "381748  11.674090  \n",
       "381749  10.967341  \n",
       "381750  10.228997  \n",
       "381751   9.740015  \n",
       "381752   8.844098  \n",
       "\n",
       "[379671 rows x 40 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window = 10\n",
    "no_of_std = 2\n",
    "df['pltp']=df.ltp.shift(1)\n",
    "#Calculate rolling mean and standard deviation using number of days set above\n",
    "rolling_mean = df['ltp'].rolling(window).mean()\n",
    "rolling_std = df['ltp'].rolling(window).std()\n",
    "#create upper and lower Bollinger bands\n",
    "df['Rolling Mean'] = rolling_mean\n",
    "df['Bollinger High'] = rolling_mean + (rolling_std * no_of_std)\n",
    "df['Bollinger Low'] = rolling_mean - (rolling_std * no_of_std)\n",
    "df['L14'] = df['ltp'].rolling(window=14).min()\n",
    "#Create the \"H14\" column\n",
    "df['H14'] = df['ltp'].rolling(window=14).max()\n",
    "#Create the \"%K\" column \n",
    "df['%K'] = 100*((df['ltp'] - df['L14']) / (df['H14'] - df['L14']) )\n",
    "#Create the \"%D\" column \n",
    "df['%D'] = df['%K'].rolling(window=3).mean()\n",
    "exp1 = df['ltp'].ewm(span=10, adjust=False).mean()\n",
    "ma5 = df['ltp'].rolling(5).mean()\n",
    "ma20 = df['ltp'].rolling(20).mean()\n",
    "ma15 = df['ltp'].rolling(15).mean()\n",
    "ma10 = df['ltp'].rolling(10).mean()\n",
    "exp2 = df['ltp'].ewm(span=20, adjust=False).mean()\n",
    "macd = exp1 - exp2\n",
    "exp3 = macd.ewm(span=9, adjust=False).mean()\n",
    "df= df.assign(macd = macd)\n",
    "df= df.assign(exp1 = exp1)\n",
    "df= df.assign(exp2 = exp2)\n",
    "df= df.assign(exp3 = exp3)\n",
    "df= df.assign(ma5 = ma5)\n",
    "df= df.assign(ma15 = ma15)\n",
    "df= df.assign(ma10 = ma10)\n",
    "df= df.assign(ma20 = ma20)\n",
    "\n",
    "avg_gain = df['ltp'].diff(1).mask(df['ltp'].diff(1)<0,0).ewm(com = 9, min_periods = 10).mean()\n",
    "avg_loss = df['ltp'].diff(1).mask(df['ltp'].diff(1)>0,0).ewm(com = 9, min_periods = 10).mean()\n",
    "df['avg_gain'] = avg_gain\n",
    "df['avg_loss'] = avg_loss\n",
    "df['rsi']=100-(100/(1+abs(avg_gain/avg_loss)))\n",
    "\n",
    "df['kelchm'] = df['ltp'].rolling(window, min_periods=window).mean()\n",
    "df['kelchu'] =((4 * df['ltp'] - 2 * df['ltp'] + df['ltp']) / 3).rolling(window, min_periods=window).mean()\n",
    "df['kelchd'] = ((-2 * df['ltp'] + 4 * df['ltp'] + df['ltp']) / 3).rolling(window, min_periods=window).mean()\n",
    "\n",
    "df['std']=df['ltp'].rolling(window, min_periods=window).std()\n",
    "\n",
    "max = df[['ltp', 'pltp']].values.max(1)\n",
    "min = df[['ltp', 'pltp']].values.min(1)\n",
    "df['High'] = max\n",
    "df[\"Low\"] = min\n",
    "df = df.assign(\n",
    "    vwap=df.eval(\n",
    "        'wgtd = ltp * volume', inplace=False\n",
    "    ).cumsum().eval('wgtd / volume')\n",
    ")\n",
    "df = df.assign(ROC = df['ltp'].diff(window)/df['ltp'].shift(window))\n",
    "df = df.assign(CCI = (df['ltp'] - df['ma5'])/ (0.015*df['ltp'].rolling(window).std()))\n",
    "df = df.assign(force = df['ltp'].diff(window) * df['volume'])\n",
    "ad = (2 * df['ltp'] - max - min) / (max - min) * df['volume']\n",
    "df['chalkin'] = ad.ewm(span=3, min_periods=3).mean() - ad.ewm(span=10, min_periods=10).mean()\n",
    "\n",
    "Range = df['High'] - df['Low']\n",
    "EX1 = Range.ewm(span=9, min_periods=9).mean()\n",
    "EX2 = EX1.ewm(span=9, min_periods=9).mean()\n",
    "Mass = EX1 / EX2\n",
    "df['mass'] = Mass.rolling(9).sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df = df.dropna()\n",
    "df['timestamp'] = pd.to_numeric(pd.to_datetime(df['timestamp']))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Following Block we create the classes for the data, to analyze what price movement that is tracked. We then convert the pandas Dataframe into numpy arrays for standatdizing the data and splitting it. We also run one-hot encoding on our classes, to help us in identifying the classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df= df.assign(act= 0)\n",
    "for i in range(df['act'].count()):\n",
    "    a = df['short'].iat[i]\n",
    "    b = df['buy'].iat[i]\n",
    "    if  a > n or a < -1 * n or b > n or b < -1 * n:  \n",
    "        s =-1\n",
    "    elif a > b:\n",
    "        s = 1   \n",
    "    elif a < b:\n",
    "        s = 2   \n",
    "    elif a and b  < 0:\n",
    "        s = 4  \n",
    "    else: \n",
    "        s = 3\n",
    "    \n",
    "    df.iat[i,-1] = s\n",
    "\n",
    "\n",
    "df = df.drop(['short', 'buy'], axis = 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "timestamp         379671\n",
      "ltp               379671\n",
      "volume            379671\n",
      "bidqty            379671\n",
      "bid               379671\n",
      "ask               379671\n",
      "askqty            379671\n",
      "pltp              379671\n",
      "Rolling Mean      379671\n",
      "Bollinger High    379671\n",
      "Bollinger Low     379671\n",
      "L14               379671\n",
      "H14               379671\n",
      "%K                379671\n",
      "%D                379671\n",
      "macd              379671\n",
      "exp1              379671\n",
      "exp2              379671\n",
      "exp3              379671\n",
      "ma5               379671\n",
      "ma15              379671\n",
      "ma10              379671\n",
      "ma20              379671\n",
      "avg_gain          379671\n",
      "avg_loss          379671\n",
      "rsi               379671\n",
      "kelchm            379671\n",
      "kelchu            379671\n",
      "kelchd            379671\n",
      "std               379671\n",
      "High              379671\n",
      "Low               379671\n",
      "vwap              379671\n",
      "ROC               379671\n",
      "CCI               379671\n",
      "force             379671\n",
      "chalkin           379671\n",
      "mass              379671\n",
      "act               379671\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.61726852e+18,  1.04345000e+03,  2.32500000e+03, ...,\n",
       "         5.14339272e+01, -1.97625000e+03,  1.78021535e+03],\n",
       "       [ 1.61726853e+18,  1.04345000e+03,  3.51300000e+03, ...,\n",
       "         4.44141009e+01, -1.93215000e+03,  1.78021535e+03],\n",
       "       [ 1.61726853e+18,  1.04325000e+03,  1.73500000e+03, ...,\n",
       "         1.55900407e+01, -1.30125000e+03, -1.16559371e+02],\n",
       "       ...,\n",
       "       [ 1.61971020e+18,  1.18575000e+03,  5.20000000e+01, ...,\n",
       "         1.30493381e+01, -1.82000000e+01, -4.68182800e+01],\n",
       "       [ 1.61971020e+18,  1.18575000e+03,  0.00000000e+00, ...,\n",
       "         1.34962720e+01,  0.00000000e+00, -4.68182800e+01],\n",
       "       [ 1.61971020e+18,  1.18575000e+03,  8.00000000e+00, ...,\n",
       "         1.40545672e+01,  2.40000000e+00, -4.68182800e+01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y = df.iloc[:,-1]\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(Y)\n",
    "print(df.count())\n",
    "X= np.array(df.iloc[:,0:-2])\n",
    "Y=np.array(Y)\n",
    "l =int( 0.9* len(X)) \n",
    "#X, Xa = X[:l,:], X[l:,:]\n",
    "#Y, Ya = Y[:l,:], Y[l:,:]\n",
    "\n",
    "scaler = StandardScaler().fit(X)\n",
    "X\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is Split into training and testing data. The split is on the lines of 1/3 Test and 2/3 Training. The final data is converted into tensors ad reshaped to be processed by our model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90521 90231 69830]\n",
      "[35307 37153 56629]\n",
      "[35307 37153 56629]\n"
     ]
    }
   ],
   "source": [
    "tscv = TimeSeriesSplit(n_splits=int((len(X))/(len(X)/2)))\n",
    "\n",
    "#for train_index, test_index in tscv.split(df) :\n",
    " #   print(train_index[-1])\n",
    "  #  print(len(X))\n",
    "   # if train_index[-1] < len(X):\n",
    "    #    X_train2, X_test2 = Y[train_index], Y[test_index]\n",
    "     #   y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "\n",
    "l =int(0.66* len(X)) \n",
    "X_train2, X_test2 = X[:l,:], X[l:,:]\n",
    "y_train1, y_test1 = Y[:l,:], Y[l:,:]\n",
    "y_d = lb.inverse_transform(y_train1)\n",
    "y_q = lb.inverse_transform(y_test1)\n",
    "#y_e = lb.inverse_transform(Ya)\n",
    "\n",
    "unique, counts = np.unique(y_d, return_counts=True)\n",
    "print ( counts)\n",
    "#print(np.asarray((unique, counts)).T)\n",
    "unique, counts = np.unique(y_q, return_counts=True)\n",
    "print ( counts)\n",
    "#unique, counts = np.unique(y_e, return_counts=True)\n",
    "print ( counts)\n",
    "\n",
    "X_train1 =  np.expand_dims(X_train2, 1)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_test1 =  np.expand_dims(X_test2, 1)\n",
    "X_trainq = tf.convert_to_tensor(X_train1, dtype=tf.float32)\n",
    "#X_train  = tf.transpose(arg, perm=[2, 0, 1])\n",
    "X_testq = tf.convert_to_tensor(X_test1, dtype=tf.float32)\n",
    "X_train1 = tf.transpose(X_trainq, perm=[0, 2, 1])\n",
    "X_test1 = tf.transpose(X_testq, perm=[0, 2, 1])\n",
    "X_train3 = tf.slice(X_train1, [0,0,0],[1,-1,1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the code for creating the model. We have used a combination of Transpose Convolutional and Convolutional filters with Echo State networks and Gated rectified Units to create this architecture. More information on this architecture can ve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 37, 64)\n",
      "0\n",
      "(None, 266, 64)\n",
      "1\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 37, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d (Conv1D)                 (None, 37, 64)       128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d (AveragePooli (None, 35, 1)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose (Conv1DTranspo (None, 37, 64)       4160        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTrans (None, 38, 64)       8256        conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTrans (None, 40, 64)       16448       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTrans (None, 44, 64)       32832       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 22, 64)       65600       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 14, 64)       98368       conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 2, 64)        147520      conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 6, 64)        131136      conv1d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_5 (Conv1D)               (None, 26, 64)       704         average_pooling1d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 37, 64)       0           conv1d_transpose[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 38, 64)       0           conv1d_transpose_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 40, 64)       0           conv1d_transpose_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 44, 64)       0           conv1d_transpose_3[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 22, 64)       0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 14, 64)       0           conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 2, 64)        0           conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 6, 64)        0           conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 26, 64)       0           conv1d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout (AlphaDropout)    (None, 37, 64)       0           leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_1 (AlphaDropout)  (None, 38, 64)       0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_2 (AlphaDropout)  (None, 40, 64)       0           leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_3 (AlphaDropout)  (None, 44, 64)       0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_4 (AlphaDropout)  (None, 22, 64)       0           leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_5 (AlphaDropout)  (None, 14, 64)       0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_6 (AlphaDropout)  (None, 2, 64)        0           leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_7 (AlphaDropout)  (None, 6, 64)        0           leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_8 (AlphaDropout)  (None, 26, 64)       0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_6 (Conv1D)               (None, 37, 64)       128         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 229, 64)      0           alpha_dropout[0][0]              \n",
      "                                                                 alpha_dropout_1[0][0]            \n",
      "                                                                 alpha_dropout_2[0][0]            \n",
      "                                                                 alpha_dropout_3[0][0]            \n",
      "                                                                 alpha_dropout_4[0][0]            \n",
      "                                                                 alpha_dropout_5[0][0]            \n",
      "                                                                 alpha_dropout_6[0][0]            \n",
      "                                                                 alpha_dropout_7[0][0]            \n",
      "                                                                 alpha_dropout_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 37, 64)       256         conv1d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 266, 64)      0           concatenate[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)       (None, 266, 64)      0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 266, 64)      0           leaky_re_lu_9[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_7 (Conv1D)               (None, 266, 64)      4160        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling1d_1 (AveragePoo (None, 264, 64)      0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTrans (None, 266, 64)      4160        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_5 (Conv1DTrans (None, 267, 64)      8256        conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_6 (Conv1DTrans (None, 269, 64)      16448       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_transpose_7 (Conv1DTrans (None, 273, 64)      32832       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_8 (Conv1D)               (None, 251, 64)      65600       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 243, 64)      98368       conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 231, 64)      147520      conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 235, 64)      131136      conv1d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 255, 64)      41024       average_pooling1d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)      (None, 266, 64)      0           conv1d_transpose_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)      (None, 267, 64)      0           conv1d_transpose_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)      (None, 269, 64)      0           conv1d_transpose_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)      (None, 273, 64)      0           conv1d_transpose_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)      (None, 251, 64)      0           conv1d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)      (None, 243, 64)      0           conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_16 (LeakyReLU)      (None, 231, 64)      0           conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_17 (LeakyReLU)      (None, 235, 64)      0           conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_18 (LeakyReLU)      (None, 255, 64)      0           conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_9 (AlphaDropout)  (None, 266, 64)      0           leaky_re_lu_10[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_10 (AlphaDropout) (None, 267, 64)      0           leaky_re_lu_11[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_11 (AlphaDropout) (None, 269, 64)      0           leaky_re_lu_12[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_12 (AlphaDropout) (None, 273, 64)      0           leaky_re_lu_13[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_13 (AlphaDropout) (None, 251, 64)      0           leaky_re_lu_14[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_14 (AlphaDropout) (None, 243, 64)      0           leaky_re_lu_15[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_15 (AlphaDropout) (None, 231, 64)      0           leaky_re_lu_16[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_16 (AlphaDropout) (None, 235, 64)      0           leaky_re_lu_17[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_17 (AlphaDropout) (None, 255, 64)      0           leaky_re_lu_18[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_13 (Conv1D)              (None, 266, 64)      4160        dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 2290, 64)     0           alpha_dropout_9[0][0]            \n",
      "                                                                 alpha_dropout_10[0][0]           \n",
      "                                                                 alpha_dropout_11[0][0]           \n",
      "                                                                 alpha_dropout_12[0][0]           \n",
      "                                                                 alpha_dropout_13[0][0]           \n",
      "                                                                 alpha_dropout_14[0][0]           \n",
      "                                                                 alpha_dropout_15[0][0]           \n",
      "                                                                 alpha_dropout_16[0][0]           \n",
      "                                                                 alpha_dropout_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 266, 64)      256         conv1d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 2556, 64)     0           concatenate_2[0][0]              \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_19 (LeakyReLU)      (None, 2556, 64)     0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2556, 64)     0           leaky_re_lu_19[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_14 (Conv1D)              (None, 2556, 64)     4160        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 2556, 64)     256         conv1d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 5112, 64)     0           dropout_1[0][0]                  \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_20 (LeakyReLU)      (None, 5112, 64)     0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 5112, 64)     0           leaky_re_lu_20[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "gru_3 (GRU)                     (None, 5112, 128)    74496       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "esn (ESN)                       (None, 128)          16640       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "esn_1 (ESN)                     (None, 128)          16640       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "esn_2 (ESN)                     (None, 128)          16640       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru_4 (GRU)                     (None, 5112, 128)    99072       gru_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_18 (AlphaDropout) (None, 128)          0           esn[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_19 (AlphaDropout) (None, 128)          0           esn_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "alpha_dropout_20 (AlphaDropout) (None, 128)          0           esn_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru_5 (GRU)                     (None, 128)          99072       gru_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 512)          0           alpha_dropout_18[0][0]           \n",
      "                                                                 alpha_dropout_19[0][0]           \n",
      "                                                                 alpha_dropout_20[0][0]           \n",
      "                                                                 gru_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 3)            1539        concatenate_5[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,387,971\n",
      "Trainable params: 1,337,667\n",
      "Non-trainable params: 50,304\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "filters = 64\n",
    "\n",
    "\n",
    "class InceptionModule(keras.layers.Layer):\n",
    "    def _init_(self, **kwargs):\n",
    "        super()._init_(**kwargs)\n",
    "     \n",
    "    def _def_Conv1DT(self, filters ,kernel_size):\n",
    "        return keras.layers.Conv1DTranspose(filters = filters, \n",
    "                                   kernel_size = kernel_size,\n",
    "                                   strides = 1, \n",
    "                                   use_bias = True )\n",
    "    \n",
    "    def _def_Conv1D(self, filters ,kernel_size):\n",
    "        return keras.layers.Conv1D(filters = filters, \n",
    "                                   kernel_size = kernel_size,\n",
    "                                   strides = 1, \n",
    "                                   #activation = 'relu',\n",
    "                                   use_bias = True )\n",
    "    \n",
    "    def _inception_module(self , inputs,n):\n",
    "\n",
    "        z_bottleneck = keras.layers.Conv1D(filters =  filters , kernel_size = 1)(inputs)\n",
    "        print(z_bottleneck.shape)\n",
    "        \n",
    "        #kernel_size_s = [11,13,15,17,19,23,29,31]\n",
    "        kernel_size_s = [1,2,4,8,16,24,36,32]\n",
    "\n",
    "        conv_list = []\n",
    "\n",
    "        for i in range(len(kernel_size_s)):\n",
    "            if i <  (len(kernel_size_s)/2) :\n",
    "                z = self._def_Conv1DT(filters = filters, kernel_size = kernel_size_s[i])(z_bottleneck)\n",
    "            else: \n",
    "                z = self._def_Conv1D(filters = filters, kernel_size = kernel_size_s[i])(z_bottleneck)\n",
    "            \n",
    "            z = keras.layers.LeakyReLU(alpha = 0.01)(z)\n",
    "            z = keras.layers.AlphaDropout(0.25)(z)\n",
    "            \n",
    "            conv_list.append(z)\n",
    "\n",
    "\n",
    "        z_max = keras.layers.AveragePooling1D(pool_size = 3, strides = 1, padding = 'valid')(inputs)\n",
    "\n",
    "        z6 = keras.layers.Conv1D(filters = filters, kernel_size = 10)(z_max)\n",
    "        z6 = keras.layers.LeakyReLU(alpha = 0.01)(z6)\n",
    "        z6 = keras.layers.AlphaDropout(0.3)(z6)\n",
    "        conv_list.append(z6)\n",
    "\n",
    "        \n",
    "        Z = keras.layers.concatenate(conv_list, axis = 1)\n",
    "        #Z = keras.layers.Dropout(0.25)(Z)\n",
    "        #Z = keras.layers.BatchNormalization()(Z)\n",
    "        #Z = keras.layers.Activation('relu')(Z)\n",
    "        \n",
    "        \n",
    "        return Z\n",
    "    \n",
    "    def _shortcut_layer(self, input_tensor , out_tensor):\n",
    "        shortcut_y = keras.layers.Conv1D(filters=int(out_tensor.shape[-1]), kernel_size=1,\n",
    "                                         padding='same', use_bias=True)(input_tensor)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "        x = keras.layers.concatenate([out_tensor, shortcut_y], axis = 1)\n",
    "        x = keras.layers.LeakyReLU(alpha = 0.01)(x)\n",
    "        x = keras.layers.Dropout(0.25)(x)\n",
    "        return x\n",
    "\n",
    "    def build_model(self, input_shape, nb_classes):\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        x = input_layer\n",
    "\n",
    "        input_res = input_layer\n",
    "\n",
    "\n",
    "        for d in range(2):\n",
    "            x = self._inception_module(x,d)\n",
    "            if d % 1== 0:\n",
    "                print(d)\n",
    "                x = self._shortcut_layer(input_res,x)\n",
    "                input_res = x\n",
    "\n",
    "        #gap_layer1 = tfa.layers.ESN(units = 128)(x)\n",
    "        x = self._shortcut_layer(input_res,x)\n",
    "        esns = []\n",
    "        z = x\n",
    "        for i in range(3):\n",
    "            esns.append( keras.layers.AlphaDropout(0)(\n",
    "                tfa.layers.ESN(units = filters*2,return_sequences = False)(input_layer)))\n",
    "            z =  keras.layers.Dropout(0.25)(\n",
    "                keras.layers.GRU(units = filters*2,return_sequences = False)(x))\n",
    "            #esns.append(z)\n",
    "        \n",
    "        \n",
    "                        \n",
    "        \n",
    "        gap_layer2 = tfa.layers.ESN(units = filters,return_sequences = True)(input_layer)\n",
    "        gap_layer2 = tfa.layers.ESN(units = filters*2,return_sequences = True)(gap_layer2)\n",
    "        gap_layer2 = tfa.layers.ESN(units = filters*2,return_sequences = False)(gap_layer2)\n",
    "        \n",
    "        gap_layer3 = keras.layers.GRU(units = filters*2, return_sequences = True)(x)\n",
    "        #\n",
    "        #gap_layer3 = keras.layers.GRU(units = filters*2,return_sequences = True)(gap_layer3)\n",
    "        gap_layer3 = keras.layers.GRU(units = filters*2,return_sequences = True)(gap_layer3)\n",
    "        gap_layer3 = keras.layers.GRU(units = filters*2,return_sequences = False)(gap_layer3)\n",
    "\n",
    "        esns.append(gap_layer3)\n",
    "        gap_layer = keras.layers.concatenate(esns,axis = 1)\n",
    "        #gap_layer = keras.layers.GRU(units = filters*2)(gap_layer)\n",
    "        #gap_layer = keras.layers.Multiply()([gap_layer3,gap_layer2])\n",
    "        #gap_layer = keras.layers.GlobalAveragePooling1D()(x,)\n",
    "        output_layer = keras.layers.Dense(nb_classes, activation='sigmoid')(gap_layer)\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "        model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(lr = 0.001),\n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "        return model\n",
    "\n",
    "    \n",
    "inception1 = InceptionModule()\n",
    "model = inception1.build_model(input_shape = tf.shape(tf.squeeze(X_train3 , axis = [0])), nb_classes = 3)\n",
    "model.summary()\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1958/1958 [==============================] - 1668s 845ms/step - loss: 1.1023 - accuracy: 0.3597 - val_loss: 1.1304 - val_accuracy: 0.3911\n",
      "Epoch 2/20\n",
      "  10/1958 [..............................] - ETA: 23:22 - loss: 1.0998 - accuracy: 0.3360"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-dc9f25fb2800>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'auto'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     save_best_only=True)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_filepath = './model_tensorflow2/adani/weights'\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='auto',\n",
    "    save_best_only=True)\n",
    "model.fit(X_train1, y_train1, batch_size= 128, verbose = 1,  epochs=20,callbacks=[model_checkpoint_callback], validation_data=(X_test1, y_test1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 95164 102664 184555]\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_json(r'Stock Data/adaniTest.json')\n",
    "#df1 = df1.head(100000)\n",
    "n = int(df1['ltp'][1]/100)\n",
    "#df1 = df1.drop(['short', 'buy','act'], axis = 1)\n",
    "\n",
    "#create results column, 3 ticks ahead \n",
    "short = df1.bid.shift(-1)\n",
    "buy = df1.ask.shift(-1)\n",
    "df1= df1.assign(short=df1.ask - short)\n",
    "df1= df1.assign(buy= -1*df1.bid + buy)\n",
    "df1 = df1[df1['short'] < n ]\n",
    "df1 = df1[df1['buy'] <  n]\n",
    "df1 = df1[df1['short'] >  -1*n]\n",
    "df1 = df1[df1['buy'] > - 1*n]\n",
    "\n",
    "window = 10\n",
    "no_of_std = 2\n",
    "df1['pltp']=df1.ltp.shift(1)\n",
    "#Calculate rolling mean and standard deviation using number of days set above\n",
    "rolling_mean = df1['ltp'].rolling(window).mean()\n",
    "rolling_std = df1['ltp'].rolling(window).std()\n",
    "#create upper and lower Bollinger bands\n",
    "df1['Rolling Mean'] = rolling_mean\n",
    "df1['Bollinger High'] = rolling_mean + (rolling_std * no_of_std)\n",
    "df1['Bollinger Low'] = rolling_mean - (rolling_std * no_of_std)\n",
    "df1['L14'] = df1['ltp'].rolling(window=14).min()\n",
    "#Create the \"H14\" column\n",
    "df1['H14'] = df1['ltp'].rolling(window=14).max()\n",
    "#Create the \"%K\" column \n",
    "df1['%K'] = 100*((df1['ltp'] - df1['L14']) / (df1['H14'] - df1['L14']) )\n",
    "#Create the \"%D\" column \n",
    "df1['%D'] = df1['%K'].rolling(window=3).mean()\n",
    "exp1 = df1['ltp'].ewm(span=10, adjust=False).mean()\n",
    "ma5 = df1['ltp'].rolling(5).mean()\n",
    "ma20 = df1['ltp'].rolling(20).mean()\n",
    "ma15 = df1['ltp'].rolling(15).mean()\n",
    "ma10 = df1['ltp'].rolling(10).mean()\n",
    "exp2 = df1['ltp'].ewm(span=20, adjust=False).mean()\n",
    "macd = exp1 - exp2\n",
    "exp3 = macd.ewm(span=9, adjust=False).mean()\n",
    "df1= df1.assign(macd = macd)\n",
    "df1= df1.assign(exp1 = exp1)\n",
    "df1= df1.assign(exp2 = exp2)\n",
    "df1= df1.assign(exp3 = exp3)\n",
    "df1= df1.assign(ma5 = ma5)\n",
    "df1= df1.assign(ma15 = ma15)\n",
    "df1= df1.assign(ma10 = ma10)\n",
    "df1= df1.assign(ma20 = ma20)\n",
    "\n",
    "avg_gain = df1['ltp'].diff(1).mask(df1['ltp'].diff(1)<0,0).ewm(com = 9, min_periods = 10).mean()\n",
    "avg_loss = df1['ltp'].diff(1).mask(df1['ltp'].diff(1)>0,0).ewm(com = 9, min_periods = 10).mean()\n",
    "df1['avg_gain'] = avg_gain\n",
    "df1['avg_loss'] = avg_loss\n",
    "df1['rsi']=100-(100/(1+abs(avg_gain/avg_loss)))\n",
    "\n",
    "df1['kelchm'] = df1['ltp'].rolling(window, min_periods=window).mean()\n",
    "df1['kelchu'] =((4 * df1['ltp'] - 2 * df1['ltp'] + df1['ltp']) / 3).rolling(window, min_periods=window).mean()\n",
    "df1['kelchd'] = ((-2 * df1['ltp'] + 4 * df1['ltp'] + df1['ltp']) / 3).rolling(window, min_periods=window).mean()\n",
    "\n",
    "df1['std']=df1['ltp'].rolling(window, min_periods=window).std()\n",
    "\n",
    "max = df1[['ltp', 'pltp']].values.max(1)\n",
    "min = df1[['ltp', 'pltp']].values.min(1)\n",
    "df1['High'] = max\n",
    "df1[\"Low\"] = min\n",
    "df1 = df1.assign(\n",
    "    vwap=df1.eval(\n",
    "        'wgtd = ltp * volume', inplace=False\n",
    "    ).cumsum().eval('wgtd / volume')\n",
    ")\n",
    "df1 = df1.assign(ROC = df1['ltp'].diff(window)/df1['ltp'].shift(window))\n",
    "df1 = df1.assign(CCI = (df1['ltp'] - df1['ma5'])/ (0.015*df1['ltp'].rolling(window).std()))\n",
    "df1 = df1.assign(force = df1['ltp'].diff(window) * df1['volume'])\n",
    "ad = (2 * df1['ltp'] - max - min) / (max - min) * df1['volume']\n",
    "df1['chalkin'] = ad.ewm(span=3, min_periods=3).mean() - ad.ewm(span=10, min_periods=10).mean()\n",
    "\n",
    "Range = df1['High'] - df1['Low']\n",
    "EX1 = Range.ewm(span=9, min_periods=9).mean()\n",
    "EX2 = EX1.ewm(span=9, min_periods=9).mean()\n",
    "Mass = EX1 / EX2\n",
    "df1['mass'] = Mass.rolling(9).sum()\n",
    "\n",
    "df1 = df1.dropna()\n",
    "df1['timestamp'] = pd.to_numeric(pd.to_datetime(df1['timestamp']))\n",
    "df1= df1.assign(act= 0)\n",
    "for i in range(df1['act'].count()):\n",
    "    a = df1['short'].iat[i]\n",
    "    b = df1['buy'].iat[i]\n",
    "    if  a > n or a < -1 * n or b > n or b < -1 * n:  \n",
    "        df1.iat[i,-1] =-1\n",
    "    elif a > b:\n",
    "        df1.iat[i,-1] =1   \n",
    "    elif a < b:\n",
    "        df1.iat[i,-1] =2   \n",
    "    elif a and b  < 0:\n",
    "        df1.iat[i,-1] =4  \n",
    "    else: \n",
    "        df1.iat[i,-1] =3    \n",
    "\n",
    "Y = df1.iloc[:,-1]\n",
    "df1 = df1.drop(['short', 'buy'], axis = 1)\n",
    "\n",
    "lb = LabelBinarizer()\n",
    "Y = lb.fit_transform(Y)\n",
    "X= np.array(df1.iloc[:,0:-2])\n",
    "Y=np.array(Y)\n",
    "y_q = lb.inverse_transform(Y)\n",
    "unique, counts = np.unique(y_q, return_counts=True)\n",
    "print ( counts)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "X =  np.expand_dims(X, 1)\n",
    "X = tf.convert_to_tensor(X, dtype=tf.float32)\n",
    "X = tf.transpose(X, perm=[0, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1028/1032 [============================>.] - ETA: 1s - loss: 1.0677 - accuracy: 0.4319"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X,Y,batch_size = 350)\n",
    "print(\"test loss, test acc:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 3 3 ... 3 3 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.40      0.19      0.26     10840\n",
      "           2       0.44      0.25      0.32     10788\n",
      "           3       0.50      0.87      0.64     14487\n",
      "\n",
      "    accuracy                           0.43     36115\n",
      "   macro avg       0.37      0.36      0.32     36115\n",
      "weighted avg       0.38      0.41      0.34     36115\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1048</td>\n",
       "      <td>2189</td>\n",
       "      <td>7603</td>\n",
       "      <td>10840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>923</td>\n",
       "      <td>2108</td>\n",
       "      <td>7757</td>\n",
       "      <td>10788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1229</td>\n",
       "      <td>1651</td>\n",
       "      <td>11607</td>\n",
       "      <td>14487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>3200</td>\n",
       "      <td>5948</td>\n",
       "      <td>26967</td>\n",
       "      <td>36115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted     1     2      3    All\n",
       "Actual                             \n",
       "1          2048  2189   6603  10840\n",
       "2          2235  2796   5757  10788\n",
       "3           729  1151  12607  14487\n",
       "All        5012  6316  24967  36115"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Yp = model.predict(x_test[2], batch_size = 256)\n",
    "y_pred = lb.inverse_transform(Yp)\n",
    "y_true = lb.inverse_transform(y_test[2])\n",
    "print(y_pred)\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#confusion_matrix(y_true, y_pred,labels = [1,2] )\n",
    "#matrix = confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print('Confusion matrix : \\n',matrix)\n",
    "\n",
    "print(classification_report(y_true, y_pred, labels=[1, 2,3]))\n",
    "\n",
    "matrix = confusion_matrix(y_true,y_pred)\n",
    "\n",
    "pd.crosstab(y_true, y_pred, rownames = ['Actual'], colnames =['Predicted'], margins = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = list(range(0, 50))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['test'], loc='upper left')\\\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend([ 'test'], loc='upper left')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
